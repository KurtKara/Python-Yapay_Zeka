{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "name": "Credit Risk Modeling - Calculating Expected Loss - Complete.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "05Vz-ukGVqLQ",
        "nli9W6_pVqLx",
        "wksVi3wlVqL2",
        "iAaXxlsHVqMS",
        "HJkZL-AkVqMv",
        "z2WwUZglVqM8",
        "V4iAozx3VqM8",
        "F0tUVoc1VqNP"
      ],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RegaipKURT/Machine-Learning-Python/blob/master/Credit_Risk_Modeling_Calculating_Expected_Loss_Complete.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d2rT8WLDG8_7",
        "colab_type": "text"
      },
      "source": [
        "# Credit Risk Modelling\n",
        "\n",
        "dataset = https://www.kaggle.com/wendykan/lending-club-loan-data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kJyXdWamVqII",
        "colab_type": "text"
      },
      "source": [
        "# Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6vBXH9RhVqIK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pl_uNQa1VqIP",
        "colab_type": "text"
      },
      "source": [
        "# Import Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KRLAa9RHVqIQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Import data.\n",
        "loan_data_preprocessed_backup = pd.read_csv('loan_data_2007_2014_preprocessed.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zuwrelx-VqIU",
        "colab_type": "text"
      },
      "source": [
        "# Explore Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RR8MRVrPVqIV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loan_data_preprocessed = loan_data_preprocessed_backup.copy()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kPOdl3IzVqIZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loan_data_preprocessed.columns.values\n",
        "# Displays all column names."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "kI9erqZ7VqIe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loan_data_preprocessed.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xfc0MtYpVqIi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loan_data_preprocessed.tail()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KK4onf8PVqIm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loan_data_defaults = loan_data_preprocessed[loan_data_preprocessed['loan_status'].isin(['Charged Off','Does not meet the credit policy. Status:Charged Off'])]\n",
        "# Here we take only the accounts that were charged-off (written-off)."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "hz2rWbXiVqIq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loan_data_defaults.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gs96MhY4VqIu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pd.options.display.max_rows = None\n",
        "# Sets the pandas dataframe options to display all columns/ rows."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j3z5nsR9VqIy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loan_data_defaults.isnull().sum()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eodUrkMrVqI2",
        "colab_type": "text"
      },
      "source": [
        "# Independent Variables"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "b80alY07VqI3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loan_data_defaults['mths_since_last_delinq'].fillna(0, inplace = True)\n",
        "# We fill the missing values with zeroes."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HpA0QfyZVqI8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#loan_data_defaults['mths_since_last_delinq'].fillna(loan_data_defaults['mths_since_last_delinq'].max() + 12, inplace=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1SKOwhy8VqI_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loan_data_defaults['mths_since_last_record'].fillna(0, inplace=True)\n",
        "# We fill the missing values with zeroes."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zkNAwriJVqJD",
        "colab_type": "text"
      },
      "source": [
        "# Dependent Variables"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "mViadvUWVqJE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loan_data_defaults['recovery_rate'] = loan_data_defaults['recoveries'] / loan_data_defaults['funded_amnt']\n",
        "# We calculate the dependent variable for the LGD model: recovery rate.\n",
        "# It is the ratio of recoveries and funded amount."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ox9mar6cVqJH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loan_data_defaults['recovery_rate'].describe()\n",
        "# Shows some descriptive statisics for the values of a column."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jURVo6T4VqJL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loan_data_defaults['recovery_rate'] = np.where(loan_data_defaults['recovery_rate'] > 1, 1, loan_data_defaults['recovery_rate'])\n",
        "loan_data_defaults['recovery_rate'] = np.where(loan_data_defaults['recovery_rate'] < 0, 0, loan_data_defaults['recovery_rate'])\n",
        "# We set recovery rates that are greater than 1 to 1 and recovery rates that are less than 0 to 0."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "crQdZw5OVqJP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loan_data_defaults['recovery_rate'].describe()\n",
        "# Shows some descriptive statisics for the values of a column."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BSdyN8ZSVqJT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loan_data_defaults['CCF'] = (loan_data_defaults['funded_amnt'] - loan_data_defaults['total_rec_prncp']) / loan_data_defaults['funded_amnt']\n",
        "# We calculate the dependent variable for the EAD model: credit conversion factor.\n",
        "# It is the ratio of the difference of the amount used at the moment of default to the total funded amount."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8MTI2sobVqJW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loan_data_defaults['CCF'].describe()\n",
        "# Shows some descriptive statisics for the values of a column."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "53vaJOYzVqJd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loan_data_defaults.to_csv('loan_data_defaults.csv')\n",
        "# We save the data to a CSV file."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "APcSbn0bVqJg",
        "colab_type": "text"
      },
      "source": [
        "# Explore Dependent Variables"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n23MJB6MVqJh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "sns.set()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mnimxm_BVqJk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.hist(loan_data_defaults['recovery_rate'], bins = 100)\n",
        "# We plot a histogram of a variable with 100 bins."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ow-tK-2pVqJn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.hist(loan_data_defaults['recovery_rate'], bins = 50)\n",
        "# We plot a histogram of a variable with 50 bins."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u6ng5ZIAVqJq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.hist(loan_data_defaults['CCF'], bins = 100)\n",
        "# We plot a histogram of a variable with 100 bins."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XCFnebk3VqJv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loan_data_defaults['recovery_rate_0_1'] = np.where(loan_data_defaults['recovery_rate'] == 0, 0, 1)\n",
        "# We create a new variable which is 0 if recovery rate is 0 and 1 otherwise."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hlaSjt25VqJy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loan_data_defaults['recovery_rate_0_1']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lZFjQAW2VqJ1",
        "colab_type": "text"
      },
      "source": [
        "# LGD Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iKF-ViNFVqJ2",
        "colab_type": "text"
      },
      "source": [
        "### Splitting Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s8BPNO9KVqJ3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p0sXD8kDVqJ5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# LGD model stage 1 datasets: recovery rate 0 or greater than 0.\n",
        "lgd_inputs_stage_1_train, lgd_inputs_stage_1_test, lgd_targets_stage_1_train, lgd_targets_stage_1_test = train_test_split(loan_data_defaults.drop(['good_bad', 'recovery_rate','recovery_rate_0_1', 'CCF'], axis = 1), loan_data_defaults['recovery_rate_0_1'], test_size = 0.2, random_state = 42)\n",
        "# Takes a set of inputs and a set of targets as arguments. Splits the inputs and the targets into four dataframes:\n",
        "# Inputs - Train, Inputs - Test, Targets - Train, Targets - Test."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RHAPMpWdVqJ8",
        "colab_type": "text"
      },
      "source": [
        "### Preparing the Inputs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pi5vJX8eVqJ9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "features_all = ['grade:A',\n",
        "'grade:B',\n",
        "'grade:C',\n",
        "'grade:D',\n",
        "'grade:E',\n",
        "'grade:F',\n",
        "'grade:G',\n",
        "'home_ownership:MORTGAGE',\n",
        "'home_ownership:NONE',\n",
        "'home_ownership:OTHER',\n",
        "'home_ownership:OWN',\n",
        "'home_ownership:RENT',\n",
        "'verification_status:Not Verified',\n",
        "'verification_status:Source Verified',\n",
        "'verification_status:Verified',\n",
        "'purpose:car',\n",
        "'purpose:credit_card',\n",
        "'purpose:debt_consolidation',\n",
        "'purpose:educational',\n",
        "'purpose:home_improvement',\n",
        "'purpose:house',\n",
        "'purpose:major_purchase',\n",
        "'purpose:medical',\n",
        "'purpose:moving',\n",
        "'purpose:other',\n",
        "'purpose:renewable_energy',\n",
        "'purpose:small_business',\n",
        "'purpose:vacation',\n",
        "'purpose:wedding',\n",
        "'initial_list_status:f',\n",
        "'initial_list_status:w',\n",
        "'term_int',\n",
        "'emp_length_int',\n",
        "'mths_since_issue_d',\n",
        "'mths_since_earliest_cr_line',\n",
        "'funded_amnt',\n",
        "'int_rate',\n",
        "'installment',\n",
        "'annual_inc',\n",
        "'dti',\n",
        "'delinq_2yrs',\n",
        "'inq_last_6mths',\n",
        "'mths_since_last_delinq',\n",
        "'mths_since_last_record',\n",
        "'open_acc',\n",
        "'pub_rec',\n",
        "'total_acc',\n",
        "'acc_now_delinq',\n",
        "'total_rev_hi_lim']\n",
        "# List of all independent variables for the models."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "okB86VvNVqKA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "features_reference_cat = ['grade:G',\n",
        "'home_ownership:RENT',\n",
        "'verification_status:Verified',\n",
        "'purpose:credit_card',\n",
        "'initial_list_status:f']\n",
        "# List of the dummy variable reference categories. "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PO5L-t7TVqKD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lgd_inputs_stage_1_train = lgd_inputs_stage_1_train[features_all]\n",
        "# Here we keep only the variables we need for the model."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hTE-ryIrVqKH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lgd_inputs_stage_1_train = lgd_inputs_stage_1_train.drop(features_reference_cat, axis = 1)\n",
        "# Here we remove the dummy variable reference categories."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fzj7CO1OVqKK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lgd_inputs_stage_1_train.isnull().sum()\n",
        "# Check for missing values. We check whether the value of each row for each column is missing or not,\n",
        "# then sum accross columns."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SfC-AGn9VqKN",
        "colab_type": "text"
      },
      "source": [
        "### Estimating the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KvWrveWfVqKN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# P values for sklearn logistic regression.\n",
        "\n",
        "# Class to display p-values for logistic regression in sklearn.\n",
        "\n",
        "from sklearn import linear_model\n",
        "import scipy.stats as stat\n",
        "\n",
        "class LogisticRegression_with_p_values:\n",
        "    \n",
        "    def __init__(self,*args,**kwargs):#,**kwargs):\n",
        "        self.model = linear_model.LogisticRegression(*args,**kwargs)#,**args)\n",
        "\n",
        "    def fit(self,X,y):\n",
        "        self.model.fit(X,y)\n",
        "        \n",
        "        #### Get p-values for the fitted model ####\n",
        "        denom = (2.0 * (1.0 + np.cosh(self.model.decision_function(X))))\n",
        "        denom = np.tile(denom,(X.shape[1],1)).T\n",
        "        F_ij = np.dot((X / denom).T,X) ## Fisher Information Matrix\n",
        "        Cramer_Rao = np.linalg.inv(F_ij) ## Inverse Information Matrix\n",
        "        sigma_estimates = np.sqrt(np.diagonal(Cramer_Rao))\n",
        "        z_scores = self.model.coef_[0] / sigma_estimates # z-score for eaach model coefficient\n",
        "        p_values = [stat.norm.sf(abs(x)) * 2 for x in z_scores] ### two tailed test for p-values\n",
        "        \n",
        "        self.coef_ = self.model.coef_\n",
        "        self.intercept_ = self.model.intercept_\n",
        "        #self.z_scores = z_scores\n",
        "        self.p_values = p_values\n",
        "        #self.sigma_estimates = sigma_estimates\n",
        "        #self.F_ij = F_ij"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bfM_LCbIVqKQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "reg_lgd_st_1 = LogisticRegression_with_p_values()\n",
        "# We create an instance of an object from the 'LogisticRegression' class.\n",
        "reg_lgd_st_1.fit(lgd_inputs_stage_1_train, lgd_targets_stage_1_train)\n",
        "# Estimates the coefficients of the object from the 'LogisticRegression' class\n",
        "# with inputs (independent variables) contained in the first dataframe\n",
        "# and targets (dependent variables) contained in the second dataframe."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0KuXkNOgVqKU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "feature_name = lgd_inputs_stage_1_train.columns.values\n",
        "# Stores the names of the columns of a dataframe in a variable."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lmv2Jb_8VqKY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "summary_table = pd.DataFrame(columns = ['Feature name'], data = feature_name)\n",
        "# Creates a dataframe with a column titled 'Feature name' and row values contained in the 'feature_name' variable.\n",
        "summary_table['Coefficients'] = np.transpose(reg_lgd_st_1.coef_)\n",
        "# Creates a new column in the dataframe, called 'Coefficients',\n",
        "# with row values the transposed coefficients from the 'LogisticRegression' object.\n",
        "summary_table.index = summary_table.index + 1\n",
        "# Increases the index of every row of the dataframe with 1.\n",
        "summary_table.loc[0] = ['Intercept', reg_lgd_st_1.intercept_[0]]\n",
        "# Assigns values of the row with index 0 of the dataframe.\n",
        "summary_table = summary_table.sort_index()\n",
        "# Sorts the dataframe by index.\n",
        "p_values = reg_lgd_st_1.p_values\n",
        "# We take the result of the newly added method 'p_values' and store it in a variable 'p_values'.\n",
        "p_values = np.append(np.nan,np.array(p_values))\n",
        "# We add the value 'NaN' in the beginning of the variable with p-values.\n",
        "summary_table['p_values'] = p_values\n",
        "# In the 'summary_table' dataframe, we add a new column, called 'p_values', containing the values from the 'p_values' variable.\n",
        "summary_table"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vODdNmQ8VqKb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "summary_table = pd.DataFrame(columns = ['Feature name'], data = feature_name)\n",
        "summary_table['Coefficients'] = np.transpose(reg_lgd_st_1.coef_)\n",
        "summary_table.index = summary_table.index + 1\n",
        "summary_table.loc[0] = ['Intercept', reg_lgd_st_1.intercept_[0]]\n",
        "summary_table = summary_table.sort_index()\n",
        "p_values = reg_lgd_st_1.p_values\n",
        "p_values = np.append(np.nan,np.array(p_values))\n",
        "summary_table['p_values'] = p_values\n",
        "summary_table"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vf-UngaLVqKf",
        "colab_type": "text"
      },
      "source": [
        "### Testing the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WimYMyNHVqKg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lgd_inputs_stage_1_test = lgd_inputs_stage_1_test[features_all]\n",
        "# Here we keep only the variables we need for the model."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LCB-P6idVqKj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lgd_inputs_stage_1_test = lgd_inputs_stage_1_test.drop(features_reference_cat, axis = 1)\n",
        "# Here we remove the dummy variable reference categories."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4uqisD-dVqKm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_hat_test_lgd_stage_1 = reg_lgd_st_1.model.predict(lgd_inputs_stage_1_test)\n",
        "# Calculates the predicted values for the dependent variable (targets)\n",
        "# based on the values of the independent variables (inputs) supplied as an argument."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O4PzG7S5VqKq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_hat_test_lgd_stage_1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_q67krDNVqKt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_hat_test_proba_lgd_stage_1 = reg_lgd_st_1.model.predict_proba(lgd_inputs_stage_1_test)\n",
        "# Calculates the predicted probability values for the dependent variable (targets)\n",
        "# based on the values of the independent variables (inputs) supplied as an argument."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GhSIiu6AVqKw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_hat_test_proba_lgd_stage_1\n",
        "# This is an array of arrays of predicted class probabilities for all classes.\n",
        "# In this case, the first value of every sub-array is the probability for the observation to belong to the first class, i.e. 0,\n",
        "# and the second value is the probability for the observation to belong to the first class, i.e. 1."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zkChH7JzVqK0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_hat_test_proba_lgd_stage_1 = y_hat_test_proba_lgd_stage_1[: ][: , 1]\n",
        "# Here we take all the arrays in the array, and from each array, we take all rows, and only the element with index 1,\n",
        "# that is, the second element.\n",
        "# In other words, we take only the probabilities for being 1."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PPP9Xsq2VqK3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_hat_test_proba_lgd_stage_1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "maYRADBSVqK6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lgd_targets_stage_1_test_temp = lgd_targets_stage_1_test"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dTJoAr4AVqK8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lgd_targets_stage_1_test_temp.reset_index(drop = True, inplace = True)\n",
        "# We reset the index of a dataframe."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sbIIJqL4VqLA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_actual_predicted_probs = pd.concat([lgd_targets_stage_1_test_temp, pd.DataFrame(y_hat_test_proba_lgd_stage_1)], axis = 1)\n",
        "# Concatenates two dataframes."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hCV8cocBVqLC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_actual_predicted_probs.columns = ['lgd_targets_stage_1_test', 'y_hat_test_proba_lgd_stage_1']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DwWsNlhiVqLH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_actual_predicted_probs.index = lgd_inputs_stage_1_test.index\n",
        "# Makes the index of one dataframe equal to the index of another dataframe."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hp_AMdVFVqLM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_actual_predicted_probs.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "05Vz-ukGVqLQ",
        "colab_type": "text"
      },
      "source": [
        "### Estimating the Аccuracy of the Мodel"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1qvbVpViVqLR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tr = 0.5\n",
        "# We create a new column with an indicator,\n",
        "# where every observation that has predicted probability greater than the threshold has a value of 1,\n",
        "# and every observation that has predicted probability lower than the threshold has a value of 0.\n",
        "df_actual_predicted_probs['y_hat_test_lgd_stage_1'] = np.where(df_actual_predicted_probs['y_hat_test_proba_lgd_stage_1'] > tr, 1, 0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "HYl-wOoYVqLW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pd.crosstab(df_actual_predicted_probs['lgd_targets_stage_1_test'], df_actual_predicted_probs['y_hat_test_lgd_stage_1'], rownames = ['Actual'], colnames = ['Predicted'])\n",
        "# Creates a cross-table where the actual values are displayed by rows and the predicted values by columns.\n",
        "# This table is known as a Confusion Matrix."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oApbrO4UVqLZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pd.crosstab(df_actual_predicted_probs['lgd_targets_stage_1_test'], df_actual_predicted_probs['y_hat_test_lgd_stage_1'], rownames = ['Actual'], colnames = ['Predicted']) / df_actual_predicted_probs.shape[0]\n",
        "# Here we divide each value of the table by the total number of observations,\n",
        "# thus getting percentages, or, rates."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yIndFAUbVqLb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "(pd.crosstab(df_actual_predicted_probs['lgd_targets_stage_1_test'], df_actual_predicted_probs['y_hat_test_lgd_stage_1'], rownames = ['Actual'], colnames = ['Predicted']) / df_actual_predicted_probs.shape[0]).iloc[0, 0] + (pd.crosstab(df_actual_predicted_probs['lgd_targets_stage_1_test'], df_actual_predicted_probs['y_hat_test_lgd_stage_1'], rownames = ['Actual'], colnames = ['Predicted']) / df_actual_predicted_probs.shape[0]).iloc[1, 1]\n",
        "# Here we calculate Accuracy of the model, which is the sum of the diagonal rates."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qsZmCkmOVqLe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import roc_curve, roc_auc_score"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0AN2u5BnVqLh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fpr, tpr, thresholds = roc_curve(df_actual_predicted_probs['lgd_targets_stage_1_test'], df_actual_predicted_probs['y_hat_test_proba_lgd_stage_1'])\n",
        "# Returns the Receiver Operating Characteristic (ROC) Curve from a set of actual values and their predicted probabilities.\n",
        "# As a result, we get three arrays: the false positive rates, the true positive rates, and the thresholds.\n",
        "# we store each of the three arrays in a separate variable."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D0WrqnHQVqLr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.plot(fpr, tpr)\n",
        "# We plot the false positive rate along the x-axis and the true positive rate along the y-axis,\n",
        "# thus plotting the ROC curve.\n",
        "plt.plot(fpr, fpr, linestyle = '--', color = 'k')\n",
        "# We plot a seconary diagonal line, with dashed line style and black color.\n",
        "plt.xlabel('False positive rate')\n",
        "# We name the x-axis \"False positive rate\".\n",
        "plt.ylabel('True positive rate')\n",
        "# We name the x-axis \"True positive rate\".\n",
        "plt.title('ROC curve')\n",
        "# We name the graph \"ROC curve\"."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j_ZioOupVqLu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "AUROC = roc_auc_score(df_actual_predicted_probs['lgd_targets_stage_1_test'], df_actual_predicted_probs['y_hat_test_proba_lgd_stage_1'])\n",
        "# Calculates the Area Under the Receiver Operating Characteristic Curve (AUROC)\n",
        "# from a set of actual values and their predicted probabilities.\n",
        "AUROC"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nli9W6_pVqLx",
        "colab_type": "text"
      },
      "source": [
        "### Saving the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R5wBQjZSVqLx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pickle"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a78sUORaVqL0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pickle.dump(reg_lgd_st_1, open('lgd_model_stage_1.sav', 'wb'))\n",
        "# Here we export our model to a 'SAV' file with file name 'lgd_model_stage_1.sav'."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wksVi3wlVqL2",
        "colab_type": "text"
      },
      "source": [
        "### Stage 2 – Linear Regression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lQJ_GaYZVqL3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lgd_stage_2_data = loan_data_defaults[loan_data_defaults['recovery_rate_0_1'] == 1]\n",
        "# Here we take only rows where the original recovery rate variable is greater than one,\n",
        "# i.e. where the indicator variable we created is equal to 1."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dfAlSiINVqL5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# LGD model stage 2 datasets: how much more than 0 is the recovery rate\n",
        "lgd_inputs_stage_2_train, lgd_inputs_stage_2_test, lgd_targets_stage_2_train, lgd_targets_stage_2_test = train_test_split(lgd_stage_2_data.drop(['good_bad', 'recovery_rate','recovery_rate_0_1', 'CCF'], axis = 1), lgd_stage_2_data['recovery_rate'], test_size = 0.2, random_state = 42)\n",
        "# Takes a set of inputs and a set of targets as arguments. Splits the inputs and the targets into four dataframes:\n",
        "# Inputs - Train, Inputs - Test, Targets - Train, Targets - Test."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7NZlCVVBVqL8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn import linear_model\n",
        "from sklearn.metrics import mean_squared_error, r2_score"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "csr35y9cVqL-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Since the p-values are obtained through certain statistics, we need the 'stat' module from scipy.stats\n",
        "import scipy.stats as stat\n",
        "\n",
        "# Since we are using an object oriented language such as Python, we can simply define our own \n",
        "# LinearRegression class (the same one from sklearn)\n",
        "# By typing the code below we will ovewrite a part of the class with one that includes p-values\n",
        "# Here's the full source code of the ORIGINAL class: https://github.com/scikit-learn/scikit-learn/blob/7b136e9/sklearn/linear_model/base.py#L362\n",
        "\n",
        "\n",
        "class LinearRegression(linear_model.LinearRegression):\n",
        "    \"\"\"\n",
        "    LinearRegression class after sklearn's, but calculate t-statistics\n",
        "    and p-values for model coefficients (betas).\n",
        "    Additional attributes available after .fit()\n",
        "    are `t` and `p` which are of the shape (y.shape[1], X.shape[1])\n",
        "    which is (n_features, n_coefs)\n",
        "    This class sets the intercept to 0 by default, since usually we include it\n",
        "    in X.\n",
        "    \"\"\"\n",
        "    \n",
        "    # nothing changes in __init__\n",
        "    def __init__(self, fit_intercept=True, normalize=False, copy_X=True,\n",
        "                 n_jobs=1):\n",
        "        self.fit_intercept = fit_intercept\n",
        "        self.normalize = normalize\n",
        "        self.copy_X = copy_X\n",
        "        self.n_jobs = n_jobs\n",
        "\n",
        "    \n",
        "    def fit(self, X, y, n_jobs=1):\n",
        "        self = super(LinearRegression, self).fit(X, y, n_jobs)\n",
        "        \n",
        "        # Calculate SSE (sum of squared errors)\n",
        "        # and SE (standard error)\n",
        "        sse = np.sum((self.predict(X) - y) ** 2, axis=0) / float(X.shape[0] - X.shape[1])\n",
        "        se = np.array([np.sqrt(np.diagonal(sse * np.linalg.inv(np.dot(X.T, X))))])\n",
        "\n",
        "        # compute the t-statistic for each feature\n",
        "        self.t = self.coef_ / se\n",
        "        # find the p-value for each feature\n",
        "        self.p = np.squeeze(2 * (1 - stat.t.cdf(np.abs(self.t), y.shape[0] - X.shape[1])))\n",
        "        return self"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sfaMYJqyVqMA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import scipy.stats as stat\n",
        "\n",
        "class LinearRegression(linear_model.LinearRegression):\n",
        "    def __init__(self, fit_intercept=True, normalize=False, copy_X=True,\n",
        "                 n_jobs=1):\n",
        "        self.fit_intercept = fit_intercept\n",
        "        self.normalize = normalize\n",
        "        self.copy_X = copy_X\n",
        "        self.n_jobs = n_jobs\n",
        "    def fit(self, X, y, n_jobs=1):\n",
        "        self = super(LinearRegression, self).fit(X, y, n_jobs)\n",
        "        sse = np.sum((self.predict(X) - y) ** 2, axis=0) / float(X.shape[0] - X.shape[1])\n",
        "        se = np.array([np.sqrt(np.diagonal(sse * np.linalg.inv(np.dot(X.T, X))))])\n",
        "        self.t = self.coef_ / se\n",
        "        self.p = np.squeeze(2 * (1 - stat.t.cdf(np.abs(self.t), y.shape[0] - X.shape[1])))\n",
        "        return self"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B3IOudNKVqME",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lgd_inputs_stage_2_train = lgd_inputs_stage_2_train[features_all]\n",
        "# Here we keep only the variables we need for the model."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e8jk9oRMVqMH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lgd_inputs_stage_2_train = lgd_inputs_stage_2_train.drop(features_reference_cat, axis = 1)\n",
        "# Here we remove the dummy variable reference categories."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AFI-kAkDVqMJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "reg_lgd_st_2 = LinearRegression()\n",
        "# We create an instance of an object from the 'LogisticRegression' class.\n",
        "reg_lgd_st_2.fit(lgd_inputs_stage_2_train, lgd_targets_stage_2_train)\n",
        "# Estimates the coefficients of the object from the 'LogisticRegression' class\n",
        "# with inputs (independent variables) contained in the first dataframe\n",
        "# and targets (dependent variables) contained in the second dataframe."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R_8Uv5AJVqML",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "feature_name = lgd_inputs_stage_2_train.columns.values\n",
        "# Stores the names of the columns of a dataframe in a variable."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "atqOhhLQVqMO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "summary_table = pd.DataFrame(columns = ['Feature name'], data = feature_name)\n",
        "# Creates a dataframe with a column titled 'Feature name' and row values contained in the 'feature_name' variable.\n",
        "summary_table['Coefficients'] = np.transpose(reg_lgd_st_2.coef_)\n",
        "# Creates a new column in the dataframe, called 'Coefficients',\n",
        "# with row values the transposed coefficients from the 'LogisticRegression' object.\n",
        "summary_table.index = summary_table.index + 1\n",
        "# Increases the index of every row of the dataframe with 1.\n",
        "summary_table.loc[0] = ['Intercept', reg_lgd_st_2.intercept_]\n",
        "# Assigns values of the row with index 0 of the dataframe.\n",
        "summary_table = summary_table.sort_index()\n",
        "# Sorts the dataframe by index.\n",
        "p_values = reg_lgd_st_2.p\n",
        "# We take the result of the newly added method 'p_values' and store it in a variable 'p_values'.\n",
        "p_values = np.append(np.nan,np.array(p_values))\n",
        "# We add the value 'NaN' in the beginning of the variable with p-values.\n",
        "summary_table['p_values'] = p_values.round(3)\n",
        "# In the 'summary_table' dataframe, we add a new column, called 'p_values', containing the values from the 'p_values' variable.\n",
        "summary_table"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hf258Ba8VqMQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "summary_table = pd.DataFrame(columns = ['Feature name'], data = feature_name)\n",
        "summary_table['Coefficients'] = np.transpose(reg_lgd_st_2.coef_)\n",
        "summary_table.index = summary_table.index + 1\n",
        "summary_table.loc[0] = ['Intercept', reg_lgd_st_2.intercept_]\n",
        "summary_table = summary_table.sort_index()\n",
        "p_values = reg_lgd_st_2.p\n",
        "p_values = np.append(np.nan,np.array(p_values))\n",
        "summary_table['p_values'] = p_values.round(3)\n",
        "summary_table"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iAaXxlsHVqMS",
        "colab_type": "text"
      },
      "source": [
        "### Stage 2 – Linear Regression Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ug_5MzyPVqMT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lgd_inputs_stage_2_test = lgd_inputs_stage_2_test[features_all]\n",
        "# Here we keep only the variables we need for the model."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "okUCr8NsVqMb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lgd_inputs_stage_2_test = lgd_inputs_stage_2_test.drop(features_reference_cat, axis = 1)\n",
        "# Here we remove the dummy variable reference categories."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Buihl4qUVqMd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lgd_inputs_stage_2_test.columns.values\n",
        "# Calculates the predicted values for the dependent variable (targets)\n",
        "# based on the values of the independent variables (inputs) supplied as an argument."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K5C5RNQkVqMf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_hat_test_lgd_stage_2 = reg_lgd_st_2.predict(lgd_inputs_stage_2_test)\n",
        "# Calculates the predicted values for the dependent variable (targets)\n",
        "# based on the values of the independent variables (inputs) supplied as an argument."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RwJPOU-pVqMh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lgd_targets_stage_2_test_temp = lgd_targets_stage_2_test"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hA9oY5qRVqMk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lgd_targets_stage_2_test_temp = lgd_targets_stage_2_test_temp.reset_index(drop = True)\n",
        "# We reset the index of a dataframe."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "weDcC4mGVqMo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pd.concat([lgd_targets_stage_2_test_temp, pd.DataFrame(y_hat_test_lgd_stage_2)], axis = 1).corr()\n",
        "# We calculate the correlation between actual and predicted values."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "Hlh_GKGeVqMs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sns.distplot(lgd_targets_stage_2_test - y_hat_test_lgd_stage_2)\n",
        "# We plot the distribution of the residuals."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LYPXWX8GVqMt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pickle.dump(reg_lgd_st_2, open('lgd_model_stage_2.sav', 'wb'))\n",
        "# Here we export our model to a 'SAV' file with file name 'lgd_model_stage_1.sav'."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HJkZL-AkVqMv",
        "colab_type": "text"
      },
      "source": [
        "### Combining Stage 1 and Stage 2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8IJxU9ZXVqMw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_hat_test_lgd_stage_2_all = reg_lgd_st_2.predict(lgd_inputs_stage_1_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pyZJMkxfVqMy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_hat_test_lgd_stage_2_all"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rc7PEgO0VqM0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_hat_test_lgd = y_hat_test_lgd_stage_1 * y_hat_test_lgd_stage_2_all\n",
        "# Here we combine the predictions of the models from the two stages."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B-knwLahVqM2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pd.DataFrame(y_hat_test_lgd).describe()\n",
        "# Shows some descriptive statisics for the values of a column."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HDIErKZvVqM4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_hat_test_lgd = np.where(y_hat_test_lgd < 0, 0, y_hat_test_lgd)\n",
        "y_hat_test_lgd = np.where(y_hat_test_lgd > 1, 1, y_hat_test_lgd)\n",
        "# We set predicted values that are greater than 1 to 1 and predicted values that are less than 0 to 0."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qoDuFqZnVqM6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pd.DataFrame(y_hat_test_lgd).describe()\n",
        "# Shows some descriptive statisics for the values of a column."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z2WwUZglVqM8",
        "colab_type": "text"
      },
      "source": [
        "# EAD Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V4iAozx3VqM8",
        "colab_type": "text"
      },
      "source": [
        "### Estimation and Interpretation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PleiEvpkVqM8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# EAD model datasets\n",
        "ead_inputs_train, ead_inputs_test, ead_targets_train, ead_targets_test = train_test_split(loan_data_defaults.drop(['good_bad', 'recovery_rate','recovery_rate_0_1', 'CCF'], axis = 1), loan_data_defaults['CCF'], test_size = 0.2, random_state = 42)\n",
        "# Takes a set of inputs and a set of targets as arguments. Splits the inputs and the targets into four dataframes:\n",
        "# Inputs - Train, Inputs - Test, Targets - Train, Targets - Test."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HEx8OwKFVqM_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ead_inputs_train.columns.values"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LjjM64i7VqNB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ead_inputs_train = ead_inputs_train[features_all]\n",
        "# Here we keep only the variables we need for the model."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RFqzv74CVqND",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ead_inputs_train = ead_inputs_train.drop(features_reference_cat, axis = 1)\n",
        "# Here we remove the dummy variable reference categories."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9WL3gYV7VqNE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "reg_ead = LinearRegression()\n",
        "# We create an instance of an object from the 'LogisticRegression' class.\n",
        "reg_ead.fit(ead_inputs_train, ead_targets_train)\n",
        "# Estimates the coefficients of the object from the 'LogisticRegression' class\n",
        "# with inputs (independent variables) contained in the first dataframe\n",
        "# and targets (dependent variables) contained in the second dataframe."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TVPM9smFVqNG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "feature_name = ead_inputs_train.columns.values"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "ygS2rpBvVqNK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "summary_table = pd.DataFrame(columns = ['Feature name'], data = feature_name)\n",
        "# Creates a dataframe with a column titled 'Feature name' and row values contained in the 'feature_name' variable.\n",
        "summary_table['Coefficients'] = np.transpose(reg_ead.coef_)\n",
        "# Creates a new column in the dataframe, called 'Coefficients',\n",
        "# with row values the transposed coefficients from the 'LogisticRegression' object.\n",
        "summary_table.index = summary_table.index + 1\n",
        "# Increases the index of every row of the dataframe with 1.\n",
        "summary_table.loc[0] = ['Intercept', reg_ead.intercept_]\n",
        "# Assigns values of the row with index 0 of the dataframe.\n",
        "summary_table = summary_table.sort_index()\n",
        "# Sorts the dataframe by index.\n",
        "p_values = reg_lgd_st_2.p\n",
        "# We take the result of the newly added method 'p_values' and store it in a variable 'p_values'.\n",
        "p_values = np.append(np.nan,np.array(p_values))\n",
        "# We add the value 'NaN' in the beginning of the variable with p-values.\n",
        "summary_table['p_values'] = p_values\n",
        "# In the 'summary_table' dataframe, we add a new column, called 'p_values', containing the values from the 'p_values' variable.\n",
        "summary_table"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lStH-fo4VqNM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "summary_table = pd.DataFrame(columns = ['Feature name'], data = feature_name)\n",
        "summary_table['Coefficients'] = np.transpose(reg_ead.coef_)\n",
        "summary_table.index = summary_table.index + 1\n",
        "summary_table.loc[0] = ['Intercept', reg_ead.intercept_]\n",
        "summary_table = summary_table.sort_index()\n",
        "p_values = reg_lgd_st_2.p\n",
        "p_values = np.append(np.nan,np.array(p_values))\n",
        "summary_table['p_values'] = p_values\n",
        "summary_table"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F0tUVoc1VqNP",
        "colab_type": "text"
      },
      "source": [
        "### Model Validation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5_JxSjvIVqNP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ead_inputs_test = ead_inputs_test[features_all]\n",
        "# Here we keep only the variables we need for the model."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WigV-mclVqNR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ead_inputs_test = ead_inputs_test.drop(features_reference_cat, axis = 1)\n",
        "# Here we remove the dummy variable reference categories."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cs9x9MWQVqNT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ead_inputs_test.columns.values"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cAiVwCVSVqNV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_hat_test_ead = reg_ead.predict(ead_inputs_test)\n",
        "# Calculates the predicted values for the dependent variable (targets)\n",
        "# based on the values of the independent variables (inputs) supplied as an argument."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xy6o5t0oVqNX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ead_targets_test_temp = ead_targets_test"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oOdFPGAzVqNZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ead_targets_test_temp = ead_targets_test_temp.reset_index(drop = True)\n",
        "# We reset the index of a dataframe."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vKUOHAsuVqNc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pd.concat([ead_targets_test_temp, pd.DataFrame(y_hat_test_ead)], axis = 1).corr()\n",
        "# We calculate the correlation between actual and predicted values."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N4eCnvBpVqNd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sns.distplot(ead_targets_test - y_hat_test_ead)\n",
        "# We plot the distribution of the residuals."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KdWNDlVaVqNf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pd.DataFrame(y_hat_test_ead).describe()\n",
        "# Shows some descriptive statisics for the values of a column."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UE_up19uVqNh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_hat_test_ead = np.where(y_hat_test_ead < 0, 0, y_hat_test_ead)\n",
        "y_hat_test_ead = np.where(y_hat_test_ead > 1, 1, y_hat_test_ead)\n",
        "# We set predicted values that are greater than 1 to 1 and predicted values that are less than 0 to 0."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gs6wVJV7VqNl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pd.DataFrame(y_hat_test_ead).describe()\n",
        "# Shows some descriptive statisics for the values of a column."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2NCV2J5OVqNn",
        "colab_type": "text"
      },
      "source": [
        "# Expected Loss"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GaAYqtOQVqNn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loan_data_preprocessed.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R2HX1WwsVqNq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loan_data_preprocessed['mths_since_last_delinq'].fillna(0, inplace = True)\n",
        "# We fill the missing values with zeroes."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ue3kLC7NVqNu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loan_data_preprocessed['mths_since_last_record'].fillna(0, inplace = True)\n",
        "# We fill the missing values with zeroes."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B4vXVWnpVqN1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loan_data_preprocessed_lgd_ead = loan_data_preprocessed[features_all]\n",
        "# Here we keep only the variables we need for the model."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8z450M_qVqN3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loan_data_preprocessed_lgd_ead = loan_data_preprocessed_lgd_ead.drop(features_reference_cat, axis = 1)\n",
        "# Here we remove the dummy variable reference categories."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mHpK46DjVqN4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loan_data_preprocessed['recovery_rate_st_1'] = reg_lgd_st_1.model.predict(loan_data_preprocessed_lgd_ead)\n",
        "# We apply the stage 1 LGD model and calculate predicted values."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t1vqJgd6VqN6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loan_data_preprocessed['recovery_rate_st_2'] = reg_lgd_st_2.predict(loan_data_preprocessed_lgd_ead)\n",
        "# We apply the stage 2 LGD model and calculate predicted values."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MM7Ir9LXVqN8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loan_data_preprocessed['recovery_rate'] = loan_data_preprocessed['recovery_rate_st_1'] * loan_data_preprocessed['recovery_rate_st_2']\n",
        "# We combine the predicted values from the stage 1 predicted model and the stage 2 predicted model\n",
        "# to calculate the final estimated recovery rate."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lCN9S72HVqN9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loan_data_preprocessed['recovery_rate'] = np.where(loan_data_preprocessed['recovery_rate'] < 0, 0, loan_data_preprocessed['recovery_rate'])\n",
        "loan_data_preprocessed['recovery_rate'] = np.where(loan_data_preprocessed['recovery_rate'] > 1, 1, loan_data_preprocessed['recovery_rate'])\n",
        "# We set estimated recovery rates that are greater than 1 to 1 and  estimated recovery rates that are less than 0 to 0."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T60GOznzVqN_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loan_data_preprocessed['LGD'] = 1 - loan_data_preprocessed['recovery_rate']\n",
        "# We calculate estimated LGD. Estimated LGD equals 1 - estimated recovery rate."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nwc_nHyfVqOB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loan_data_preprocessed['LGD'].describe()\n",
        "# Shows some descriptive statisics for the values of a column."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "17gRIdF_VqOC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loan_data_preprocessed['CCF'] = reg_ead.predict(loan_data_preprocessed_lgd_ead)\n",
        "# We apply the EAD model to calculate estimated credit conversion factor."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UMO1gVLJVqOE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loan_data_preprocessed['CCF'] = np.where(loan_data_preprocessed['CCF'] < 0, 0, loan_data_preprocessed['CCF'])\n",
        "loan_data_preprocessed['CCF'] = np.where(loan_data_preprocessed['CCF'] > 1, 1, loan_data_preprocessed['CCF'])\n",
        "# We set estimated CCF that are greater than 1 to 1 and  estimated CCF that are less than 0 to 0."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t_ggD-9_VqOG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loan_data_preprocessed['EAD'] = loan_data_preprocessed['CCF'] * loan_data_preprocessed_lgd_ead['funded_amnt']\n",
        "# We calculate estimated EAD. Estimated EAD equals estimated CCF multiplied by funded amount."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WPKaG05vVqOI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loan_data_preprocessed['EAD'].describe()\n",
        "# Shows some descriptive statisics for the values of a column."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lCY22GRiVqOM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loan_data_preprocessed.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zE_L-sUOVqOO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loan_data_inputs_train = pd.read_csv('loan_data_inputs_train.csv')\n",
        "# We import data to apply the PD model."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Kfs-gVMVqOP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loan_data_inputs_test = pd.read_csv('loan_data_inputs_test.csv')\n",
        "# We import data to apply the PD model."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WxJWrszFVqOT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loan_data_inputs_pd = pd.concat([loan_data_inputs_train, loan_data_inputs_test], axis = 0)\n",
        "# We concatenate the two dataframes along the rows."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JYRlIG6GVqOX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loan_data_inputs_pd.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pE3QKB4sVqOZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loan_data_inputs_pd.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kJzrUITMVqOe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loan_data_inputs_pd = loan_data_inputs_pd.set_index('Unnamed: 0')\n",
        "# We set the index of the dataframe to the values of a specific column. "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bd4Y6zycVqOg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loan_data_inputs_pd.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qgIRRGOZVqOo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "features_all_pd = ['grade:A',\n",
        "'grade:B',\n",
        "'grade:C',\n",
        "'grade:D',\n",
        "'grade:E',\n",
        "'grade:F',\n",
        "'grade:G',\n",
        "'home_ownership:RENT_OTHER_NONE_ANY',\n",
        "'home_ownership:OWN',\n",
        "'home_ownership:MORTGAGE',\n",
        "'addr_state:ND_NE_IA_NV_FL_HI_AL',\n",
        "'addr_state:NM_VA',\n",
        "'addr_state:NY',\n",
        "'addr_state:OK_TN_MO_LA_MD_NC',\n",
        "'addr_state:CA',\n",
        "'addr_state:UT_KY_AZ_NJ',\n",
        "'addr_state:AR_MI_PA_OH_MN',\n",
        "'addr_state:RI_MA_DE_SD_IN',\n",
        "'addr_state:GA_WA_OR',\n",
        "'addr_state:WI_MT',\n",
        "'addr_state:TX',\n",
        "'addr_state:IL_CT',\n",
        "'addr_state:KS_SC_CO_VT_AK_MS',\n",
        "'addr_state:WV_NH_WY_DC_ME_ID',\n",
        "'verification_status:Not Verified',\n",
        "'verification_status:Source Verified',\n",
        "'verification_status:Verified',\n",
        "'purpose:educ__sm_b__wedd__ren_en__mov__house',\n",
        "'purpose:credit_card',\n",
        "'purpose:debt_consolidation',\n",
        "'purpose:oth__med__vacation',\n",
        "'purpose:major_purch__car__home_impr',\n",
        "'initial_list_status:f',\n",
        "'initial_list_status:w',\n",
        "'term:36',\n",
        "'term:60',\n",
        "'emp_length:0',\n",
        "'emp_length:1',\n",
        "'emp_length:2-4',\n",
        "'emp_length:5-6',\n",
        "'emp_length:7-9',\n",
        "'emp_length:10',\n",
        "'mths_since_issue_d:<38',\n",
        "'mths_since_issue_d:38-39',\n",
        "'mths_since_issue_d:40-41',\n",
        "'mths_since_issue_d:42-48',\n",
        "'mths_since_issue_d:49-52',\n",
        "'mths_since_issue_d:53-64',\n",
        "'mths_since_issue_d:65-84',\n",
        "'mths_since_issue_d:>84',\n",
        "'int_rate:<9.548',\n",
        "'int_rate:9.548-12.025',\n",
        "'int_rate:12.025-15.74',\n",
        "'int_rate:15.74-20.281',\n",
        "'int_rate:>20.281',\n",
        "'mths_since_earliest_cr_line:<140',\n",
        "'mths_since_earliest_cr_line:141-164',\n",
        "'mths_since_earliest_cr_line:165-247',\n",
        "'mths_since_earliest_cr_line:248-270',\n",
        "'mths_since_earliest_cr_line:271-352',\n",
        "'mths_since_earliest_cr_line:>352',\n",
        "'inq_last_6mths:0',\n",
        "'inq_last_6mths:1-2',\n",
        "'inq_last_6mths:3-6',\n",
        "'inq_last_6mths:>6',\n",
        "'acc_now_delinq:0',\n",
        "'acc_now_delinq:>=1',\n",
        "'annual_inc:<20K',\n",
        "'annual_inc:20K-30K',\n",
        "'annual_inc:30K-40K',\n",
        "'annual_inc:40K-50K',\n",
        "'annual_inc:50K-60K',\n",
        "'annual_inc:60K-70K',\n",
        "'annual_inc:70K-80K',\n",
        "'annual_inc:80K-90K',\n",
        "'annual_inc:90K-100K',\n",
        "'annual_inc:100K-120K',\n",
        "'annual_inc:120K-140K',\n",
        "'annual_inc:>140K',\n",
        "'dti:<=1.4',\n",
        "'dti:1.4-3.5',\n",
        "'dti:3.5-7.7',\n",
        "'dti:7.7-10.5',\n",
        "'dti:10.5-16.1',\n",
        "'dti:16.1-20.3',\n",
        "'dti:20.3-21.7',\n",
        "'dti:21.7-22.4',\n",
        "'dti:22.4-35',\n",
        "'dti:>35',\n",
        "'mths_since_last_delinq:Missing',\n",
        "'mths_since_last_delinq:0-3',\n",
        "'mths_since_last_delinq:4-30',\n",
        "'mths_since_last_delinq:31-56',\n",
        "'mths_since_last_delinq:>=57',\n",
        "'mths_since_last_record:Missing',\n",
        "'mths_since_last_record:0-2',\n",
        "'mths_since_last_record:3-20',\n",
        "'mths_since_last_record:21-31',\n",
        "'mths_since_last_record:32-80',\n",
        "'mths_since_last_record:81-86',\n",
        "'mths_since_last_record:>=86']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZBEjXE1mVqOs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ref_categories_pd = ['grade:G',\n",
        "'home_ownership:RENT_OTHER_NONE_ANY',\n",
        "'addr_state:ND_NE_IA_NV_FL_HI_AL',\n",
        "'verification_status:Verified',\n",
        "'purpose:educ__sm_b__wedd__ren_en__mov__house',\n",
        "'initial_list_status:f',\n",
        "'term:60',\n",
        "'emp_length:0',\n",
        "'mths_since_issue_d:>84',\n",
        "'int_rate:>20.281',\n",
        "'mths_since_earliest_cr_line:<140',\n",
        "'inq_last_6mths:>6',\n",
        "'acc_now_delinq:0',\n",
        "'annual_inc:<20K',\n",
        "'dti:>35',\n",
        "'mths_since_last_delinq:0-3',\n",
        "'mths_since_last_record:0-2']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9d5uneVLVqOu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loan_data_inputs_pd_temp = loan_data_inputs_pd[features_all_pd]\n",
        "# Here we keep only the variables we need for the model."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LzZfkeIfVqOv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loan_data_inputs_pd_temp = loan_data_inputs_pd_temp.drop(ref_categories_pd, axis = 1)\n",
        "# Here we remove the dummy variable reference categories."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T3WD8rkcVqOy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loan_data_inputs_pd_temp.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8BL3kETEVqOz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pickle"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0aUN0YiLVqO1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "reg_pd = pickle.load(open('pd_model.sav', 'rb'))\n",
        "# We import the PD model, stored in the 'pd_model.sav' file."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zw-xdFoMVqO3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "reg_pd.model.predict_proba(loan_data_inputs_pd_temp)[: ][: , 0]\n",
        "# We apply the PD model to caclulate estimated default probabilities."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KWYBgYSFVqO6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loan_data_inputs_pd['PD'] = reg_pd.model.predict_proba(loan_data_inputs_pd_temp)[: ][: , 0]\n",
        "# We apply the PD model to caclulate estimated default probabilities."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pulaASSoVqO7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loan_data_inputs_pd['PD'].head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wnjjwmk7VqO9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loan_data_inputs_pd['PD'].describe()\n",
        "# Shows some descriptive statisics for the values of a column."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7CAQTXZwVqO-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loan_data_preprocessed_new = pd.concat([loan_data_preprocessed, loan_data_inputs_pd], axis = 1)\n",
        "# We concatenate the dataframes where we calculated LGD and EAD and the dataframe where we calculated PD along the columns."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DMkzdH8AVqPB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loan_data_preprocessed_new.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Aes2Ps94VqPD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loan_data_preprocessed_new.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jOjcLB0uVqPE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loan_data_preprocessed_new['EL'] = loan_data_preprocessed_new['PD'] * loan_data_preprocessed_new['LGD'] * loan_data_preprocessed_new['EAD']\n",
        "# We calculate Expected Loss. EL = PD * LGD * EAD."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BOwQ3Tg7VqPG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loan_data_preprocessed_new['EL'].describe()\n",
        "# Shows some descriptive statisics for the values of a column."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ha5aRtlHVqPI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loan_data_preprocessed_new[['funded_amnt', 'PD', 'LGD', 'EAD', 'EL']].head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sn8vmgcUVqPJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loan_data_preprocessed_new['funded_amnt'].describe()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OZS-zpQEVqPL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loan_data_preprocessed_new['EL'].sum()\n",
        "# Total Expected Loss for all loans."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EwVF_qlJVqPM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loan_data_preprocessed_new['funded_amnt'].sum()\n",
        "# Total funded amount for all loans."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "Iw9RtNBfVqPO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loan_data_preprocessed_new['EL'].sum() / loan_data_preprocessed_new['funded_amnt'].sum()\n",
        "# Total Expected Loss as a proportion of total funded amount for all loans.\n",
        "####\n",
        "####\n",
        "####\n",
        "# THE END."
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}